{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Model Development\n",
        "This notebook implements a TF-IDF + SVM baseline for contract clause classification using the LegalBench CUAD dataset."
      ],
      "metadata": {
        "id": "TzqFD77TbJoX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1kfHE2mbBNq"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Preprocess Dataset"
      ],
      "metadata": {
        "id": "xYBwy01NbRTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = load_dataset(\"nguha/legalbench\", \"cuad_audit_rights\", trust_remote_code=True)\n",
        "df = pd.DataFrame(dataset['test'])  # Using test split for demo; adjust as needed\n",
        "df['cleaned_text'] = df['text'].apply(lambda x: x.strip().lower())\n",
        "df['label'] = df['answer'].apply(lambda x: 1 if x.lower() == 'yes' else 0)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['label'], test_size=0.2, stratify=df['label'], random_state=42)\n",
        "print(f'Training set size: {len(X_train)}, Test set size: {len(X_test)}')"
      ],
      "metadata": {
        "id": "uXt0JqO9bPZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Vectorization and SVM Training"
      ],
      "metadata": {
        "id": "z3tXbqQtbWeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train SVM\n",
        "svm = SVC(kernel='linear', random_state=42)\n",
        "svm.fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "id": "BfxAJVYMbSAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate SVM and Visualize"
      ],
      "metadata": {
        "id": "GCu_ViZRbZHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate SVM\n",
        "y_pred = svm.predict(X_test_tfidf)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('SVM Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PioG0P2ZbZuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Model and Vectorizer"
      ],
      "metadata": {
        "id": "KX-Em2vgbePY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model and vectorizer\n",
        "import joblib\n",
        "joblib.dump(svm, 'svm_baseline_model.pkl')\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')"
      ],
      "metadata": {
        "id": "QVnP2leRbfqi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}